{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "fatal: destination path 'HMP_Dataset' already exists and is not an empty directory.\r\n"
                }
            ], 
            "source": "! git clone https://github.com/wchill/HMP_Dataset.git"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "HMP_Dataset\r\n"
                }
            ], 
            "source": "! ls"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Brush_teeth\tDrink_glass  Getup_bed\t  Pour_water\t Use_telephone\r\nClimb_stairs\tEat_meat     impdata.py   README.txt\t Walk\r\nComb_hair\tEat_soup     Liedown_bed  Sitdown_chair\r\nDescend_stairs\tfinal.py     MANUAL.txt   Standup_chair\r\n"
                }
            ], 
            "source": "! ls HMP_Dataset/"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accelerometer-2011-03-24-10-07-02-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-10-16-02-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-10-46-25-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-11-14-00-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-13-09-29-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-13-17-06-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-13-31-22-drink_glass-f1.txt\r\nAccelerometer-2011-03-24-16-08-10-drink_glass-f2.txt\r\nAccelerometer-2011-03-24-16-08-29-drink_glass-f2.txt\r\nAccelerometer-2011-04-05-18-55-33-drink_glass-f1.txt\r\nAccelerometer-2011-04-08-17-33-35-drink_glass-f3.txt\r\nAccelerometer-2011-04-08-17-35-00-drink_glass-f3.txt\r\nAccelerometer-2011-04-08-18-10-09-drink_glass-m4.txt\r\nAccelerometer-2011-04-11-12-55-39-drink_glass-f1.txt\r\nAccelerometer-2011-04-11-13-17-55-drink_glass-f1.txt\r\nAccelerometer-2011-04-12-21-43-48-drink_glass-m8.txt\r\nAccelerometer-2011-04-12-21-44-55-drink_glass-m8.txt\r\nAccelerometer-2011-05-30-21-06-15-drink_glass-f1.txt\r\nAccelerometer-2011-05-30-21-06-42-drink_glass-f1.txt\r\nAccelerometer-2011-05-30-21-07-10-drink_glass-f1.txt\r\nAccelerometer-2011-05-30-21-51-35-drink_glass-m2.txt\r\nAccelerometer-2011-05-30-21-51-59-drink_glass-m2.txt\r\nAccelerometer-2011-05-30-21-52-25-drink_glass-m2.txt\r\nAccelerometer-2011-05-31-15-12-05-drink_glass-f1.txt\r\nAccelerometer-2011-05-31-15-12-36-drink_glass-f1.txt\r\nAccelerometer-2011-05-31-15-13-09-drink_glass-f1.txt\r\nAccelerometer-2011-05-31-16-35-12-drink_glass-f1.txt\r\nAccelerometer-2011-05-31-16-35-41-drink_glass-f1.txt\r\nAccelerometer-2011-05-31-16-37-39-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-13-57-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-14-22-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-14-49-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-15-19-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-15-49-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-20-46-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-21-52-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-23-15-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-24-51-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-28-50-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-30-43-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-14-33-59-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-15-04-40-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-15-09-37-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-15-14-42-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-15-25-43-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-44-44-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-45-39-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-47-29-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-49-14-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-53-24-drink_glass-f1.txt\r\nAccelerometer-2011-06-01-16-57-10-drink_glass-f1.txt\r\nAccelerometer-2011-06-02-16-51-25-drink_glass-f4.txt\r\nAccelerometer-2011-06-02-16-51-58-drink_glass-f4.txt\r\nAccelerometer-2011-06-02-16-52-53-drink_glass-f4.txt\r\nAccelerometer-2011-06-02-17-19-56-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-20-17-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-20-47-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-23-53-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-24-39-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-29-13-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-29-50-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-30-51-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-32-31-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-40-40-drink_glass-m1.txt\r\nAccelerometer-2011-06-02-17-52-26-drink_glass-m1.txt\r\nAccelerometer-2012-03-23-03-47-02-drink_glass-m9.txt\r\nAccelerometer-2012-03-23-03-47-36-drink_glass-m9.txt\r\nAccelerometer-2012-03-23-03-54-54-drink_glass-m9.txt\r\nAccelerometer-2012-03-26-04-53-07-drink_glass-f2.txt\r\nAccelerometer-2012-03-26-04-56-11-drink_glass-f2.txt\r\nAccelerometer-2012-03-26-05-02-06-drink_glass-m3.txt\r\nAccelerometer-2012-03-26-05-03-53-drink_glass-m3.txt\r\nAccelerometer-2012-05-25-18-30-30-drink_glass-f4.txt\r\nAccelerometer-2012-05-25-18-31-18-drink_glass-f4.txt\r\nAccelerometer-2012-05-25-18-32-32-drink_glass-f4.txt\r\nAccelerometer-2012-05-25-18-33-57-drink_glass-f4.txt\r\nAccelerometer-2012-05-25-18-36-27-drink_glass-f4.txt\r\nAccelerometer-2012-05-28-17-42-29-drink_glass-m1.txt\r\nAccelerometer-2012-05-28-17-44-02-drink_glass-m1.txt\r\nAccelerometer-2012-05-28-17-44-31-drink_glass-m1.txt\r\nAccelerometer-2012-05-28-17-47-23-drink_glass-m1.txt\r\nAccelerometer-2012-05-28-17-47-49-drink_glass-m1.txt\r\nAccelerometer-2012-05-28-17-50-04-drink_glass-m1.txt\r\nAccelerometer-2012-05-29-16-42-17-drink_glass-f2.txt\r\nAccelerometer-2012-05-29-16-44-12-drink_glass-f2.txt\r\nAccelerometer-2012-05-29-16-48-07-drink_glass-f2.txt\r\nAccelerometer-2012-05-29-17-11-01-drink_glass-m3.txt\r\nAccelerometer-2012-05-29-17-20-28-drink_glass-m3.txt\r\nAccelerometer-2012-05-30-19-51-49-drink_glass-f2.txt\r\nAccelerometer-2012-05-30-19-53-19-drink_glass-f2.txt\r\nAccelerometer-2012-05-30-19-53-49-drink_glass-f2.txt\r\nAccelerometer-2012-05-30-19-54-48-drink_glass-f2.txt\r\nAccelerometer-2012-05-30-19-57-08-drink_glass-m3.txt\r\nAccelerometer-2012-05-30-19-58-10-drink_glass-m3.txt\r\nAccelerometer-2012-05-30-19-58-44-drink_glass-m3.txt\r\nAccelerometer-2012-05-30-19-59-40-drink_glass-m3.txt\r\nAccelerometer-2012-05-30-21-48-13-drink_glass-m2.txt\r\nAccelerometer-2012-05-30-21-48-45-drink_glass-m2.txt\r\nAccelerometer-2012-05-30-22-10-16-drink_glass-m2.txt\r\nAccelerometer-2012-05-30-22-10-40-drink_glass-m2.txt\r\n"
                }
            ], 
            "source": "! ls HMP_Dataset/Drink_glass/"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql.types import StructType, StructField, IntegerType\n\nschema = StructType([StructField(\"x\",IntegerType(),True),\n                     StructField(\"y\",IntegerType(),True),\n                     StructField(\"z\",IntegerType(),True)])"
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 46, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['heapdump.20180817.215756.12210.0008.phd',\n 'HMP_Dataset',\n 'Snap.20180817.215735.12210.0004.trc',\n 'Snap.20180817.215749.12210.0007.trc',\n 'javacore.20180817.215735.12210.0003.txt',\n 'Snap.20180817.215756.12210.0012.trc',\n 'core.20180817.215735.12210.0001.dmp',\n 'heapdump.20180817.215749.12210.0005.phd',\n 'Snap.20180817.215756.12210.0013.trc',\n 'javacore.20180817.215756.12210.0010.txt',\n 'javacore.20180817.215749.12210.0006.txt',\n 'core.9415',\n 'javacore.20180817.215756.12210.0011.txt',\n 'javacore.20180817.215839.12210.0015.txt',\n 'Snap.20180817.215839.12210.0016.trc',\n 'heapdump.20180817.215756.12210.0009.phd',\n 'heapdump.20180817.215735.12210.0002.phd']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import os\nos.listdir()"
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 47, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['README.txt',\n 'Climb_stairs',\n 'Getup_bed',\n 'MANUAL.txt',\n 'final.py',\n 'Eat_soup',\n 'Comb_hair',\n 'Liedown_bed',\n 'Sitdown_chair',\n 'Eat_meat',\n 'Descend_stairs',\n 'Brush_teeth',\n 'impdata.py',\n 'Pour_water',\n 'Walk',\n '.git',\n 'Drink_glass',\n 'Standup_chair',\n '.idea',\n 'Use_telephone']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "os.listdir(\"HMP_Dataset\")"
        }, 
        {
            "execution_count": 48, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "file_list = os.listdir('HMP_Dataset/')"
        }, 
        {
            "execution_count": 49, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 49, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['Climb_stairs',\n 'Getup_bed',\n 'Eat_soup',\n 'Comb_hair',\n 'Liedown_bed',\n 'Sitdown_chair',\n 'Eat_meat',\n 'Descend_stairs',\n 'Brush_teeth',\n 'Pour_water',\n 'Drink_glass',\n 'Standup_chair',\n 'Use_telephone']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "file_list_filtered = [s for s in file_list if '_' in s]\nfile_list_filtered"
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45189)\nTraceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accelerometer-2011-05-30-20-54-39-climb_stairs-f1.txt\n"
                }, 
                {
                    "ename": "Py4JNetworkError", 
                    "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:45189)", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque", 
                        "\nDuring handling of the above exception, another exception occurred:\n", 
                        "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused", 
                        "\nDuring handling of the above exception, another exception occurred:\n", 
                        "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-50-b9a9fa4f95ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delimiter'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HMP_Dataset/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataFrameReader\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrameReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spark)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    879\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    834\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:45189)"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "df = None\n\nfrom pyspark.sql.functions import lit\n\nfor category in file_list_filtered:\n    data_files = os.listdir('HMP_Dataset/' + category)\n    \n    for data_file in data_files:\n        print(data_file)\n        temp_df = spark.read.option('header','false').option('delimiter',' ').csv('HMP_Dataset/' + category + '/' + data_file,schema=schema)\n        temp_df = temp_df.withColumn('Class',lit(category))\n        temp_df = temp_df.withColumn('Source',lit(data_file))\n        \n        if df is None:\n            df = temp_df\n        else:\n            df = df.union(temp_df)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import StringIndexer\nprint('Imported StringIndexer')\n\nindexer = StringIndexer(inputCol = 'Class',outputCol = 'ClassIndex')\nindexed = indexer.fit(df).transform(df)\nindexed.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import OneHotEncoder\nprint('Imported OneHotEncoder')\n\nencoder = OneHotEncoder(inputCol='ClassIndex',outputCol='CategoryVec')\nencoded = encoder.transform(indexed)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "encoded.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.linalg import Vector\nfrom pyspark.ml.feature import VectorAssembler\nprint('Imported VectorAssembler')\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],outputCol=\"features\")\nfeatures_vectorized = vectorAssembler.transform(encoded)\nfeatures_vectorized.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import Nomalizer\n\nnormalizer = Normalizer(inputCol=\"features\",outputCol = \"features_normed\",p=1.0)\nfeatures_normed = normalizer.transform(features_vectorized)\nfeatures_normed.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[indexer,encoder,vectorAssembler,normalizer])\n\nmodel = pipeline.fit(df)\nprediction = model.transform(df)\nprediction.show()\n"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}